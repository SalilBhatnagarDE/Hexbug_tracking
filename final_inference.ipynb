{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8880e06f",
   "metadata": {},
   "source": [
    "### Define all functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94f9234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make models\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "from transformers import DetrConfig, DetrForObjectDetection\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import DetrImageProcessor\n",
    "\n",
    "def make_model_processor(dir_path):\n",
    "\n",
    "    dir_path = dir_path\n",
    "\n",
    "    class Detr(pl.LightningModule):\n",
    "        def __init__(self, lr, lr_backbone, weight_decay):\n",
    "            super().__init__()\n",
    "            # replace COCO classification head with custom head\n",
    "            # we specify the \"no_timm\" variant here to not rely on the timm library\n",
    "            # for the convolutional backbone\n",
    "            self.model = DetrForObjectDetection.from_pretrained(dir_path,\n",
    "                                                                revision=\"no_timm\",\n",
    "                                                                num_labels=1,\n",
    "                                                                ignore_mismatched_sizes=True)\n",
    "            # Set all parameters as trainable\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "            # see https://github.com/PyTorchLightning/pytorch-lightning/pull/1896\n",
    "            self.lr = lr\n",
    "            self.lr_backbone = lr_backbone\n",
    "            self.weight_decay = weight_decay\n",
    "\n",
    "        def forward(self, pixel_values, pixel_mask):\n",
    "            outputs = self.model(pixel_values=pixel_values, pixel_mask=pixel_mask)\n",
    "\n",
    "            return outputs\n",
    "\n",
    "        def common_step(self, batch, batch_idx):\n",
    "            pixel_values = batch[\"pixel_values\"]\n",
    "            pixel_mask = batch[\"pixel_mask\"]\n",
    "            labels = [{k: v.to(self.device) for k, v in t.items()} for t in batch[\"labels\"]]\n",
    "\n",
    "            outputs = self.model(pixel_values=pixel_values, pixel_mask=pixel_mask, labels=labels)\n",
    "\n",
    "            loss = outputs.loss\n",
    "            loss_dict = outputs.loss_dict\n",
    "\n",
    "            return loss, loss_dict\n",
    "\n",
    "        def training_step(self, batch, batch_idx):\n",
    "            loss, loss_dict = self.common_step(batch, batch_idx)\n",
    "            # logs metrics for each training_step,\n",
    "            # and the average across the epoch\n",
    "            self.log(\"training_loss\", loss)\n",
    "            for k, v in loss_dict.items():\n",
    "                self.log(\"train_\" + k, v.item())\n",
    "\n",
    "            return loss\n",
    "\n",
    "        def validation_step(self, batch, batch_idx):\n",
    "            loss, loss_dict = self.common_step(batch, batch_idx)\n",
    "            self.log(\"validation_loss\", loss)\n",
    "            for k, v in loss_dict.items():\n",
    "                self.log(\"validation_\" + k, v.item())\n",
    "\n",
    "            return loss\n",
    "\n",
    "        def configure_optimizers(self):\n",
    "            param_dicts = [\n",
    "                {\"params\": [p for n, p in self.named_parameters() if \"backbone\" not in n and p.requires_grad]},\n",
    "                {\n",
    "                    \"params\": [p for n, p in self.named_parameters() if \"backbone\" in n and p.requires_grad],\n",
    "                    \"lr\": self.lr_backbone,\n",
    "                },\n",
    "            ]\n",
    "            optimizer = torch.optim.AdamW(param_dicts, lr=self.lr,\n",
    "                                          weight_decay=self.weight_decay)\n",
    "\n",
    "            return optimizer\n",
    "\n",
    "        def train_dataloader(self):\n",
    "            return train_dataloader\n",
    "\n",
    "        def val_dataloader(self):\n",
    "            return val_dataloader\n",
    "\n",
    "    # make preprocessor\n",
    "    processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "\n",
    "    # Make model object as per above class\n",
    "    model = Detr(lr=1e-4, lr_backbone=1e-5, weight_decay=1e-4)\n",
    "    \n",
    "    return model, processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d970f1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best checkpoint\n",
    "def load_checkpoint(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path,map_location=torch.device('cpu'))\n",
    "\n",
    "    # Load the model state dictionary from the checkpoint\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a12c376",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load test videos ::\n",
    "# For leaderboard, load videos first\n",
    "\n",
    "def load_test_videos(path):\n",
    "    \"\"\"\n",
    "    This function returns all trainings videos and the annotations as binary masks (1 at the positions where a Hexbug is located).\n",
    "    All frames are resized and normalized. \n",
    "    \"\"\"\n",
    "    X = []\n",
    "    i=0\n",
    "    for vid in os.listdir(path):\n",
    "\n",
    "        path = Path(path)\n",
    "        if \".mp4\" in vid:\n",
    "            temp_save = []\n",
    "            \n",
    "            cap = cv2.VideoCapture(str(path / vid))\n",
    "            ret, frame = cap.read()     \n",
    "            org_shape = frame.shape    \n",
    "            \n",
    "            z = 0  # frame counter\n",
    "            while ret:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame_history = []\n",
    "                \n",
    "                # Append to lists\n",
    "                temp_save.append(frame)\n",
    "                \n",
    "                ret, frame = cap.read()  # read next frame\n",
    "                z += 1  # increase frame counter\n",
    "            X.append(temp_save)\n",
    "\n",
    "    X = (X)\n",
    "    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cb7d243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial prediction before association algorithm\n",
    "\n",
    "def get_initial_predictions(X, threshold):\n",
    "\n",
    "    threshold = threshold\n",
    "    initial_predictions = []\n",
    "    predicted_hex = []\n",
    "\n",
    "    for video in X:\n",
    "\n",
    "        tmp = []\n",
    "\n",
    "        for i, img in enumerate(video):\n",
    "\n",
    "            #We can use the image_id in target to know which image it is\n",
    "            encoding = processor(images=img, annotations=None, return_tensors=\"pt\")\n",
    "            pixel_values = encoding[\"pixel_values\"].squeeze() # remove batch dimension\n",
    "\n",
    "            device = torch.device( \"cuda\")\n",
    "            pixel_values = pixel_values.unsqueeze(0).to(device)\n",
    "            model.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "              # forward pass to get class logits and bounding boxes\n",
    "              outputs = model(pixel_values=pixel_values, pixel_mask=None)\n",
    "\n",
    "            # postprocess model outputs\n",
    "            width, height = img.shape[1], img.shape[0]\n",
    "            postprocessed_outputs = processor.post_process_object_detection(outputs,\n",
    "                                                                            target_sizes=[(height, width)],\n",
    "                                                                            threshold=threshold)\n",
    "            results = postprocessed_outputs[0]\n",
    "\n",
    "\n",
    "            for ids, (score, label, (xmin, ymin, xmax, ymax))  in enumerate(zip(results['scores'].tolist(), results['labels'].tolist(), results['boxes'].tolist())):\n",
    "                center = (xmin+32.5, ymin+32.5)\n",
    "                array = [int(i),int(ids),xmin+32.5, ymin+32.5]\n",
    "                np.set_printoptions(suppress=True)\n",
    "                farray = np.array(array)\n",
    "\n",
    "                frame, ids, x ,y = farray\n",
    "\n",
    "                if int(ids+1)<=4: \n",
    "                    # we create a dictionary for each roi in the correct format\n",
    "                    e = {\n",
    "                            't': frame,\n",
    "                            'hexbug': ids,\n",
    "                            'x': y,\n",
    "                            'y': x\n",
    "                        }\n",
    "                    tmp.append(e)\n",
    "\n",
    "        total_frames = int(i)+1\n",
    "        n = round(len(tmp)/total_frames)\n",
    "        predicted_hex.append(n)\n",
    "\n",
    "        initial_predictions.append(tmp)\n",
    "        \n",
    "    return initial_predictions, predicted_hex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0795291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(x1, y1, x2, y2):\n",
    "    return ((x2 - x1)**2 + (y2 - y1)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d5ad4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final predictions after applying associative alogorithm\n",
    "\n",
    "def get_final_predictions(X, threshold, predicted_hex):\n",
    "    threshold = threshold\n",
    "    final_predictions = []\n",
    "    n_hex = predicted_hex\n",
    "\n",
    "    for m, video in enumerate(X):\n",
    "\n",
    "        tmp = []\n",
    "        tmp_array = []\n",
    "\n",
    "        for i, img in enumerate(video):\n",
    "\n",
    "            #We can use the image_id in target to know which image it is\n",
    "            encoding = processor(images=img, annotations=None, return_tensors=\"pt\")\n",
    "            pixel_values = encoding[\"pixel_values\"].squeeze() # remove batch dimension\n",
    "\n",
    "            device = torch.device( \"cuda\")\n",
    "            pixel_values = pixel_values.unsqueeze(0).to(device)\n",
    "            model.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "              # forward pass to get class logits and bounding boxes\n",
    "              outputs = model(pixel_values=pixel_values, pixel_mask=None)\n",
    "\n",
    "            # postprocess model outputs\n",
    "            width, height = img.shape[1], img.shape[0]\n",
    "            postprocessed_outputs = processor.post_process_object_detection(outputs,\n",
    "                                                                            target_sizes=[(height, width)],\n",
    "                                                                            threshold=threshold)\n",
    "            results = postprocessed_outputs[0]\n",
    "\n",
    "            image_pred_history = []\n",
    "            for ids, (score, label, (xmin, ymin, xmax, ymax))  in enumerate(zip(results['scores'].tolist(), results['labels'].tolist(), results['boxes'].tolist())):\n",
    "                pred_n_hexs = len(results['scores'].tolist())\n",
    "                center = (xmin+32.5, ymin+32.5)\n",
    "                array = [int(i),int(ids),xmin+32.5, ymin+32.5]\n",
    "                farray = np.array(array)\n",
    "                frame, ids, x ,y = farray\n",
    "\n",
    "                if int(ids+1)<=n_hex[m]:\n",
    "                    if int(ids+1)<=4: \n",
    "                        # we create a dictionary for each roi in the correct format\n",
    "                        e = {\n",
    "                                't': frame,\n",
    "                                'hexbug': ids,\n",
    "                                'x': y,\n",
    "                                'y': x\n",
    "                            }\n",
    "                        image_pred_history.append(farray)\n",
    "                        tmp.append(e)\n",
    "\n",
    "            tmp_array.append(image_pred_history)\n",
    "\n",
    "            if (int(ids+1)<n_hex[m]):\n",
    "                difference = n_hex[m] - int(ids+1)\n",
    "                for n in range(len(tmp_array) - 1, -1, -1):\n",
    "                    if len(tmp_array[n]) == n_hex[m]:\n",
    "\n",
    "                        associative_list = []\n",
    "                        a_list = tmp_array[n]\n",
    "                        # Iterate over elements of list B\n",
    "                        for b_element in image_pred_history:\n",
    "                            min_distance = float('inf')  # Initialize minimum distance as infinity\n",
    "                            associated_a_element = None  # Initialize associated A element as None\n",
    "\n",
    "                            # Iterate over elements of list A\n",
    "                            for index, a_element in enumerate(a_list):\n",
    "                                if not index in associative_list:\n",
    "                                    # Extract frame ID, hexbug ID, x, and y coordinates from list A element\n",
    "                                    a_frame_id, a_hexbug_id, a_x, a_y = a_element\n",
    "\n",
    "                                    # Calculate distance between B element and A element\n",
    "                                    distance = calculate_distance(a_x, a_y, b_element[2], b_element[3])\n",
    "\n",
    "                                    # Check if the distance is smaller than the minimum distance\n",
    "                                    if distance < min_distance:\n",
    "                                        min_distance = distance\n",
    "                                        associated_a_element = a_element\n",
    "                                        associated_a_element_index = index\n",
    "                            associative_list.append(associated_a_element_index)                        \n",
    "\n",
    "                        expected_size = n_hex[m]\n",
    "                        expected_range = range(0, expected_size)\n",
    "                        missing_elements = list(set(expected_range) - set(associative_list))\n",
    "\n",
    "                        for missed_number, missed in enumerate(missing_elements):                     \n",
    "                            x = tmp_array[n][missed][2]\n",
    "                            y = tmp_array[n][missed][3]\n",
    "                            e = {\n",
    "                            't': int(frame),\n",
    "                            'hexbug': int(ids+missed_number+1),\n",
    "                            'x': y,\n",
    "                            'y': x}\n",
    "                            tmp.append(e)\n",
    "                        break\n",
    "\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "\n",
    "\n",
    "        final_predictions.append(tmp)\n",
    "        \n",
    "    return final_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83bb9b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving function to generate csv files\n",
    "import pandas as pd\n",
    "def save_list(list_with_values: list, path: str):\n",
    "    df = pd.DataFrame(list_with_values)\n",
    "    df = df.sort_values(by = ['hexbug', 't'],ignore_index=True) # we sort the values by hexbug and frame\n",
    "    # now the values are in the correct order, so we save the csv file\n",
    "    print('Saving to csv')\n",
    "    df.to_csv(path)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2144cf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\salil\\anaconda3\\lib\\site-packages\\transformers\\models\\detr\\image_processing_detr.py:780: FutureWarning: The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n",
      "  warnings.warn(\n",
      "Some weights of DetrForObjectDetection were not initialized from the model checkpoint at C:/Salil Data/Salil/Salil FAU/MSc ACES/Sem 2 Courses/Tracking Olympiad/Trained/DETR resnet50 default/Full_trainable/5_queries/auxloss_true and are newly initialized because the shapes did not match:\n",
      "- model.query_position_embeddings.weight: found shape torch.Size([100, 256]) in the checkpoint and torch.Size([5, 256]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "dir_path = \"C:/Salil Data/Salil/Salil FAU/MSc ACES/Sem 2 Courses/Tracking Olympiad/Trained/DETR resnet50 default/Full_trainable/5_queries/auxloss_true\"\n",
    "# dir_path = \"C:/Salil Data/Salil/Salil FAU/MSc ACES/Sem 2 Courses/Tracking Olympiad/Trained/DETR resnet50 default/Full_trainable/5_queries/auxloss_true/bboxloss_inc/Gaussian_Color/V30_resnet101\"\n",
    "model, processor = make_model_processor(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc1aea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"C:/Salil Data/Salil/Salil FAU/MSc ACES/Sem 2 Courses/Tracking Olympiad/Trained/DETR resnet50 default/Full_trainable/5_queries/auxloss_true/bboxloss_inc/logstensorboard/DETR_Full_trainable_ogr_size_5_queries/version_2/checkpoints/epoch=24-step=3700.ckpt\"\n",
    "load_checkpoint(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a62b8903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where test videos are located\n",
    "dir_path_videos = 'C:/Salil Data/Salil/Salil FAU/MSc ACES/Sem 2 Courses/Tracking Olympiad/Leaderboard test data/videos'\n",
    "\n",
    "# Define path where the test data is located\n",
    "path_test_vids = Path(dir_path_videos)\n",
    "X = load_test_videos(dir_path_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aba0a160",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_predictions, predicted_hex = get_initial_predictions(X, 0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "37798314",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = get_final_predictions(X, 0.65, predicted_hex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5aa1db8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to csv\n",
      "Done\n",
      "Saving to csv\n",
      "Done\n",
      "Saving to csv\n",
      "Done\n",
      "Saving to csv\n",
      "Done\n",
      "Saving to csv\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Save predictions\n",
    "\n",
    "for i, prediction in enumerate(final_predictions):\n",
    "    save_list(prediction, f\"C:\\\\Salil Data\\\\Salil\\\\Salil FAU\\\\MSc ACES\\\\Sem 2 Courses\\\\Tracking Olympiad\\\\Leaderboard test data\\\\videos\\\\test00{i+1}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "839c9d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Video : 1 is : 12074.967777515163\n",
      "Score for Video : 2 is : 780.8893762497265\n",
      "Score for Video : 3 is : 107609.820368868\n",
      "Score for Video : 4 is : 14508.24232231819\n",
      "Score for Video : 5 is : 133358.14230055085\n",
      "Total score :            268332.06214550196\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:\\Salil Data\\Salil\\Salil FAU\\MSc ACES\\Sem 2 Courses\\\\Tracking Olympiad\\\\Git Repository\")\n",
    "\n",
    "from traco_external import get_score\n",
    "from traco_external.get_score import *\n",
    "\n",
    "total_score = 0\n",
    "for i in range(len(final_predictions)):\n",
    "    score = get_score(f\"C:/Salil Data/Salil/Salil FAU/MSc ACES/Sem 2 Courses/Tracking Olympiad/Leaderboard test data/videos/test00{i+1}.csv\", f\"C:/Salil Data/Salil/hexbugtest/gt/test00{i+1}.csv\", log=True)\n",
    "    print(\"Score for Video :\", i+1, \"is :\", score)\n",
    "    total_score += score\n",
    "print(\"Total score :           \", total_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee291ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
